import{_ as t,c as a,o as n,ae as i}from"./chunks/framework.Dh1jimFm.js";const d=JSON.parse('{"title":"Reimagining Assessment in an AI-Enabled Health Professions World","description":"","frontmatter":{},"headers":[],"relativePath":"06-assessment-in-an-ai-enabled-world.md","filePath":"06-assessment-in-an-ai-enabled-world.md"}'),s={name:"06-assessment-in-an-ai-enabled-world.md"};function o(l,e,r,h,c,u){return n(),a("div",null,e[0]||(e[0]=[i('<h1 id="reimagining-assessment-in-an-ai-enabled-health-professions-world" tabindex="-1">Reimagining Assessment in an AI-Enabled Health Professions World <a class="header-anchor" href="#reimagining-assessment-in-an-ai-enabled-health-professions-world" aria-label="Permalink to &quot;Reimagining Assessment in an AI-Enabled Health Professions World&quot;">​</a></h1><p>After reviewing your emergent scholarship principles, I see why you find current AI-focused assessment &quot;solutions&quot; problematic. They attempt to apply linear thinking to a complex, interconnected challenge. Rather than seeing AI as something to work against, emergent scholarship offers a pathway to integrate AI into meaningful assessment that actually enhances our ability to evaluate professional competence.</p><h2 id="current-assessment-landscape" tabindex="-1">Current Assessment Landscape <a class="header-anchor" href="#current-assessment-landscape" aria-label="Permalink to &quot;Current Assessment Landscape&quot;">​</a></h2><p>The typical responses to AI in assessment—banning it, creating &quot;AI-proof&quot; tests, or increasing difficulty—all share a fundamental flaw: they position AI as external to the learning ecosystem rather than an emerging part of it. These approaches:</p><ul><li>Assume learning exists in a vacuum separate from tools</li><li>Fail to recognize how professional practice is already being transformed by AI</li><li>Miss opportunities to evaluate how professionals will actually work in AI-enabled environments</li><li>Often focus on lower-order skills that AI can readily replicate</li></ul><h2 id="a-path-forward-using-emergent-scholarship-principles" tabindex="-1">A Path Forward Using Emergent Scholarship Principles <a class="header-anchor" href="#a-path-forward-using-emergent-scholarship-principles" aria-label="Permalink to &quot;A Path Forward Using Emergent Scholarship Principles&quot;">​</a></h2><h3 id="knowledge-through-connection" tabindex="-1">Knowledge Through Connection <a class="header-anchor" href="#knowledge-through-connection" aria-label="Permalink to &quot;Knowledge Through Connection&quot;">​</a></h3><p>Instead of treating assessment as isolation of individual knowledge, we might reimagine it as evaluating how effectively learners connect knowledge systems:</p><ul><li>Assess how students navigate between AI tools and human expertise</li><li>Evaluate their ability to synthesize information from multiple sources</li><li>Measure how they leverage networks to solve complex problems</li></ul><p><strong>Practical example:</strong> A clinical reasoning assessment where students must appropriately integrate AI-generated differential diagnoses with patient context, known limitations of the AI system, and their own clinical judgment.</p><h3 id="information-flow-through-networks" tabindex="-1">Information Flow Through Networks <a class="header-anchor" href="#information-flow-through-networks" aria-label="Permalink to &quot;Information Flow Through Networks&quot;">​</a></h3><p>Assessment could evaluate how effectively students:</p><ul><li>Direct appropriate queries to AI systems</li><li>Critically evaluate AI-generated information</li><li>Know when and how to seek human expertise</li><li>Effectively communicate AI-informed decisions to patients and colleagues</li></ul><p><strong>Practical example:</strong> Evaluating medical students&#39; ability to craft effective prompts for clinical decision support AI, interpret the outputs, and communicate their reasoning process to patients in understandable terms.</p><h3 id="identity-through-community" tabindex="-1">Identity Through Community <a class="header-anchor" href="#identity-through-community" aria-label="Permalink to &quot;Identity Through Community&quot;">​</a></h3><p>Assessment might explore:</p><ul><li>How students position themselves in relationship to AI tools</li><li>Their ethical reasoning about appropriate AI boundaries</li><li>Their ability to participate in communities of practice that include both human and AI components</li></ul><p><strong>Practical example:</strong> Reflective assessments where students articulate their developing professional identity in relation to AI tools, discussing cases where they chose to rely on or override AI recommendations.</p><h3 id="innovation-through-openness" tabindex="-1">Innovation Through Openness <a class="header-anchor" href="#innovation-through-openness" aria-label="Permalink to &quot;Innovation Through Openness&quot;">​</a></h3><p>Assessment could reward:</p><ul><li>Novel applications of AI in clinical reasoning</li><li>Identification of AI limitations and workarounds</li><li>Contributions to improving AI systems through feedback</li></ul><p><strong>Practical example:</strong> Portfolios documenting students&#39; innovations in clinical workflows that thoughtfully integrate AI tools.</p><h3 id="meaning-through-medium" tabindex="-1">Meaning Through Medium <a class="header-anchor" href="#meaning-through-medium" aria-label="Permalink to &quot;Meaning Through Medium&quot;">​</a></h3><p>We could assess:</p><ul><li>Students&#39; ability to select appropriate mediums (AI or non-AI) for different tasks</li><li>How they translate between AI outputs and human understanding</li><li>Their skill in representing complex information effectively</li></ul><p><strong>Practical example:</strong> Evaluating how students translate algorithm-based risk scores into meaningful shared decision-making conversations with patients.</p><h3 id="value-through-engagement" tabindex="-1">Value Through Engagement <a class="header-anchor" href="#value-through-engagement" aria-label="Permalink to &quot;Value Through Engagement&quot;">​</a></h3><p>Assessment could focus on:</p><ul><li>How students engage stakeholders in AI-informed decisions</li><li>Their ability to preserve human connection while using AI tools</li><li>How they assess the impact of AI-assisted interventions</li></ul><p><strong>Practical example:</strong> Observed clinical encounters where faculty evaluate how students maintain therapeutic relationships while incorporating AI-generated treatment recommendations.</p><h3 id="sustainability-through-ecology" tabindex="-1">Sustainability Through Ecology <a class="header-anchor" href="#sustainability-through-ecology" aria-label="Permalink to &quot;Sustainability Through Ecology&quot;">​</a></h3><p>We might evaluate:</p><ul><li>Students&#39; awareness of AI biases and limitations</li><li>Their ability to create sustainable workflows involving AI</li><li>How they balance efficiency with holistic care</li></ul><p><strong>Practical example:</strong> Longitudinal assessment of students&#39; development of sustainable AI-augmented clinical practice patterns that prevent burnout while improving care.</p><h2 id="practical-implementation-path" tabindex="-1">Practical Implementation Path <a class="header-anchor" href="#practical-implementation-path" aria-label="Permalink to &quot;Practical Implementation Path&quot;">​</a></h2><ol><li><p><strong>Start with authentic assessment contexts</strong>: Build assessments around real-world scenarios where AI would naturally be present</p></li><li><p><strong>Involve multiple stakeholders</strong>: Include patients, practicing clinicians, technology experts, and students in assessment design</p></li><li><p><strong>Develop graduated competencies</strong>: Create developmental milestones for AI-augmented professional practice</p></li><li><p><strong>Use multimodal assessment</strong>: Combine observations, portfolios, workplace assessments, and AI-augmented simulations</p></li><li><p><strong>Focus on metacognition</strong>: Assess students&#39; ability to reflect on when and how to use AI appropriately</p></li><li><p><strong>Create feedback loops</strong>: Ensure assessment findings inform curriculum development in an iterative cycle</p></li><li><p><strong>Model transparency</strong>: Be explicit about how AI is used in the assessment process itself</p></li></ol><p>The path forward isn&#39;t about creating assessments that resist AI—it&#39;s about creating assessments that authentically evaluate how health professionals will work with AI. This requires us to be clear about what uniquely human capabilities we value in our professionals, while acknowledging that the boundaries between human and machine cognition will continue to evolve.</p><p>By applying emergent scholarship principles, we can create assessment systems that are adaptive, contextual, and focused on how students navigate complex systems—exactly what they&#39;ll need to do in their professional futures.</p>',38)]))}const m=t(s,[["render",o]]);export{d as __pageData,m as default};
