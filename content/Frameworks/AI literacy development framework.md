---
title: AI literacy development framework
type: framework
aliases:
  - AI literacy embedding framework
  - embedded AI literacy
description: >-
  A framework for embedding AI literacy development into existing modules and
  courses, enabling students to develop AI capability while learning
  disciplinary content.
author: '[[Michael Rowe]]'
date: 2026-02-01
updated: 2026-02-01
tags:
  - AI-literacy
  - curriculum-design
category:
  - AI and technology
related:
  - '[[AI literacy]]'
  - '[[AI literacy for academics]]'
  - '[[common architecture of literacy]]'
draft: false
enableToc: true
---

> [!tip] Learning AI through use, not about it
> This framework enables students to develop AI literacy *while* learning disciplinary content. Rather than teaching AI as a separate topic, embed AI engagement into existing learning activities so students develop capability through authentic practice.

## Purpose

This framework guides educators in embedding AI literacy development into existing modules and courses. The goal is not to teach *about* AI as a separate topic, but to help students develop [[AI literacy|AI literacy]] capability *through* using AI to engage with disciplinary content.

Students learn to use AI effectively by using it for authentic learning tasks. The module content remains primary; AI literacy develops as a by-product of structured engagement.

## The six dimensions of AI literacy

AI literacy is multidimensional capability that cannot be reduced to any single skill. When embedding AI into learning activities, consider which dimensions each activity develops:

### 1. Access and recognition

Understanding what AI systems are and recognising when they are relevant. Students learn to distinguish AI from search engines or databases, understand AI as language-based cognitive extension, and identify when AI might help versus hinder their learning.

**In practice:** Activities that ask students to consider *whether* to use AI for a task, not just *how*.

### 2. Critical evaluation

The capacity to assess AI outputs for quality, accuracy, and reliability. Students learn that AI can hallucinate, recognise the difference between fluent and accurate responses, and maintain appropriate scepticism while remaining open to genuine assistance.

**In practice:** Activities requiring verification of AI outputs against authoritative sources or disciplinary standards.

### 3. Functional application

The practical ability to use AI systems effectively for specific purposes. Students develop competence with prompting, learn to structure requests for better outputs, and deploy AI capabilities appropriately.

**In practice:** Structured prompting exercises with clear expectations for output quality.

### 4. Creation and communication

The skill to generate meaningful outputs through collaboration with AI. Students move beyond consumption to production—using AI to develop arguments, decompose problems, and communicate ideas while maintaining their distinctive voice.

**In practice:** Activities where AI supports the creative process but students remain responsible for the intellectual contribution.

### 5. Ethical awareness and responsibility

Understanding the social, ethical, and professional implications of AI engagement. Students learn about transparency, attribution, academic integrity, and when AI use might undermine rather than support their learning goals.

**In practice:** Explicit discussion of appropriate AI use for each activity, with clear expectations.

### 6. Contextual judgement and metacognition

Developing taste and professional judgement about meaningful AI engagement. Students learn to distinguish genuine competence from mere familiarity, recognise when AI helps versus hinders, and develop domain-specific judgement that evolves with experience.

**In practice:** Reflection activities that ask students to evaluate the quality of their AI engagement, not just their outputs.

## Developmental progression

AI literacy develops through four stages. Design activities that meet students where they are and scaffold progression:

### Stage 1: Foundation

**Focus:** Understanding AI as cognitive partner, not tool or search engine.

**Key learning:**
- AI generates responses based on patterns, not retrieved information
- Conversational engagement produces better results than transactional queries
- You and AI make different kinds of mistakes (complementary errors)
- Critical evaluation is always your responsibility

**Activity characteristics:**
- Clear, structured prompting tasks with explicit guidance
- Immediate comparison between simple queries and contextual prompts
- Reflection on what AI contributed versus what required human judgement

### Stage 2: Substitution

**Focus:** Using AI to complete existing tasks more efficiently.

**Key learning:**
- Structured prompting (Role, Goal, Instruct, Discuss) improves outputs
- Not every task benefits from AI—learn to select appropriately
- Track time honestly, including all revision
- Efficiency serves learning goals, not productivity for its own sake

**Activity characteristics:**
- Bounded tasks with clear structure and expectations
- Time tracking to evaluate actual efficiency gains
- Honest evaluation: did AI actually help with this task?

### Stage 3: Adaptation

**Focus:** Reshaping learning approaches around AI capabilities.

**Key learning:**
- Build genuine competence, not just familiarity
- Test understanding immediately rather than assuming comprehension
- Use staged complexity: basic idea → contextual understanding → procedural detail
- Develop arguments through structured dialogue

**Activity characteristics:**
- Extended engagement building understanding through conversation
- Multiple rounds of testing and refinement
- Activities that require application, not just comprehension

### Stage 4: Transformation

**Focus:** Integrating AI into sustained practice with professional judgement.

**Key learning:**
- Context management enables more sophisticated engagement
- Taste and judgement develop through reflective practice
- Structural integration sustains practice better than willpower
- Ongoing maintenance and adaptation required

**Activity characteristics:**
- Ongoing projects with accumulated context
- Metacognitive reflection on AI engagement patterns
- Student-directed decisions about when and how to use AI

## Designing embedded activities

### Principles for embedding AI literacy

**1. Start with the learning outcome, not the technology**
Design activities that achieve disciplinary learning goals. Then consider how AI engagement might support that learning while also developing AI literacy.

**2. Make AI use authentic, not artificial**
Students develop literacy through genuine use. Avoid contrived "use AI for this" exercises. Instead, create situations where AI engagement is a natural part of the learning process.

**3. Require critical evaluation, not acceptance**
Every AI-assisted activity should include evaluation of AI outputs against disciplinary standards. Students learn that AI assistance requires verification.

**4. Build in reflection**
Include structured reflection on the AI engagement process, not just the output. What worked? What didn't? When did AI help versus hinder?

**5. Progress through stages deliberately**
Early activities provide more structure and guidance. Later activities give students more autonomy to make judgements about AI use.

### Activity design template

For each embedded activity, consider:

| Element | Questions to address |
|---------|---------------------|
| **Learning outcome** | What disciplinary knowledge or skill does this develop? |
| **AI literacy dimensions** | Which dimensions does this activity develop? |
| **Developmental stage** | Foundation, Substitution, Adaptation, or Transformation? |
| **Structure provided** | How much prompting guidance do students receive? |
| **Evaluation requirements** | How must students verify or evaluate AI outputs? |
| **Reflection component** | What metacognitive questions will students address? |
| **Success criteria** | What distinguishes effective from ineffective AI engagement? |

### Example activity types by stage

**Foundation activities:**
- Compare outputs from simple query versus structured prompt for the same task
- Identify errors or limitations in AI-generated content about course topics
- Explain to AI what you already know about a topic and evaluate its response

**Substitution activities:**
- Use AI to generate first-draft summaries of course readings, then evaluate and refine
- Create study materials (flashcards, practice questions) with AI assistance
- Draft routine professional communications with AI support

**Adaptation activities:**
- Build understanding of complex concepts through staged AI dialogue
- Develop arguments by testing reasoning with AI as interlocutor
- Decompose complex problems with AI support before solving

**Transformation activities:**
- Maintain ongoing project context across multiple AI sessions
- Design personal AI engagement strategies for different learning tasks
- Evaluate when AI engagement serves learning goals versus undermines them

## Assessing AI literacy development

### What to assess

Assessment should focus on the quality of AI engagement, not just the quality of outputs:

- **Process documentation:** How did students structure their AI engagement?
- **Critical evaluation evidence:** How did students verify and refine AI outputs?
- **Metacognitive reflection:** What did students learn about effective AI use?
- **Judgement quality:** Did students make appropriate decisions about when and how to use AI?

### Assessment approaches

**Transparency requirements:** Students document their AI use, including prompts, outputs, and revisions. This develops honest practice and provides evidence for assessment.

**Comparative analysis:** Students compare AI-assisted and unassisted approaches to similar tasks, reflecting on the differences.

**Reflection portfolios:** Students maintain ongoing documentation of their AI literacy development across the module.

**Calibrated self-assessment:** Students assess their own AI literacy against clear criteria, with instructor feedback on calibration accuracy.

## Implementation guidance

### Module-level integration

1. **Audit existing activities:** Identify where AI engagement could support disciplinary learning while developing AI literacy
2. **Sequence deliberately:** Ensure activities progress through developmental stages appropriately
3. **Be explicit about expectations:** Clarify AI use policies for each activity rather than blanket policies
4. **Build in reflection points:** Regular opportunities for students to evaluate their AI engagement patterns

### Avoiding common pitfalls

**Don't:** Create artificial "use AI for this" exercises disconnected from learning goals
**Do:** Embed AI engagement into authentic learning tasks

**Don't:** Allow unstructured AI use without guidance or reflection
**Do:** Provide scaffolding appropriate to developmental stage

**Don't:** Focus only on outputs without attention to process
**Do:** Assess quality of AI engagement alongside quality of outputs

**Don't:** Assume students will develop literacy through exposure alone
**Do:** Design deliberate progression with explicit attention to all six dimensions

**Don't:** Apply blanket AI policies across all activities
**Do:** Set context-appropriate expectations for each learning task

## Quick reference: The framework at a glance

```
┌─────────────────────────────────────────────────────────────────┐
│                    SIX DIMENSIONS OF AI LITERACY                │
├─────────────────────────────────────────────────────────────────┤
│ 1. Access & Recognition    │ 4. Creation & Communication       │
│ 2. Critical Evaluation     │ 5. Ethical Awareness              │
│ 3. Functional Application  │ 6. Contextual Judgement           │
└─────────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────────┐
│                  DEVELOPMENTAL PROGRESSION                      │
├─────────────────────────────────────────────────────────────────┤
│ Foundation → Substitution → Adaptation → Transformation        │
│ (Structure)   (Efficiency)   (Reshaping)   (Integration)        │
└─────────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────────┐
│                    DESIGN PRINCIPLES                            │
├─────────────────────────────────────────────────────────────────┤
│ • Start with learning outcomes, not technology                  │
│ • Make AI use authentic, not artificial                         │
│ • Require critical evaluation, not acceptance                   │
│ • Build in reflection on process                                │
│ • Progress through stages deliberately                          │
└─────────────────────────────────────────────────────────────────┘
```

---

## Sources

This framework synthesises concepts from:

- Long, D., & Magerko, B. (2020). What is AI Literacy? Competencies and Design Considerations. *Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems*.
- UNESCO. (2024). Guidance for generative AI in education and research.
- Allen, L. K., & Kendeou, P. (2023). ED-AI Lit: An Interdisciplinary Framework for AI Literacy in Education. *Policy Insights from the Behavioral and Brain Sciences*.
- Mollick, E., & Mollick, L. (2023). Assigning AI: Seven approaches for students, with prompts. *SSRN Electronic Journal*.
