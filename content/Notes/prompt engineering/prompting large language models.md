Many people approach prompting like they approach internet search. They provide a few keywords and expect 'the answer'. But [[generative AI is not search]].

Approach language model prompting as if you were having a conversation with a person. In particular, a *skilful conversation with a domain expert*, where generative AI is the expert. Your job is to use the prompt to extract the most valuable expertise from the model.

---

tags: #prompt-engineering #generative-ai 
related: [[few-shot prompting]]; [[zero-shot prompting]]; [[chain-of-thought prompting]]; [[auto-prompting]]; [[role, goal, instruct, discuss framework for writing LLM prompts]]
shared: 

**References**

- Hardman, D. P. (2023). Structured Prompting for Educators. Dr Phil's Newsletter, Powered by DOMSÔ∏è AI. Retrieved from https://drphilippahardman.substack.com/p/structured-prompting-for-educators
- Mollick, E. (2023). Now is the time for grimoires. One Useful Thing. Retrieved from https://www.oneusefulthing.org/p/now-is-the-time-for-grimoires
- Mollick, E, and Mollick, L. (2023). Practical AI for Instructors and Students Part 3: Prompting AI.

---

**Footnotes**

[^1]: It can be confusing to talk about the model being online. After all, you're online because that's the only way you could be interacting with the model. However, you're connected to the chatbot i.e. the user-facing part of the system. The chatbot in turn, connects to the model that's running on a server somewhere. And it may not be the case that the model is connected to the internet.
[^2]: Another common example I see often is the CIDI framework: Context, Instruction, Details, and Input.