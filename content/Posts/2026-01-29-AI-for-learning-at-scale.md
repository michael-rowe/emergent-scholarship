---
title: 'AI for learning at scale: Why I''m optimistic'
type: post
aliases:
  - Enthusiasm for AI clearly articulated
  - AI for learning at scale
description: >-
  Generative AI presents serious ethical challenges in education—to academic
  integrity, to equity, to the nature of learning itself. This post acknowledges
  these concerns while arguing that AI also represents an unprecedented
  opportunity for learning at scale, particularly for the kinds of personalised,
  adaptive learning that have always been theoretically desirable but
  practically impossible to deliver. For health professions educators committed
  to expanding access to quality education, this opportunity deserves serious,
  open-minded consideration.
meta-description: >-
  Why I'm optimistic about AI for learning at scale, despite the very real
  ethical concerns.
keyphrase: AI for learning at scale
author: '[[Michael Rowe]]'
date: 2026-01-29
updated: 2026-01-30
tags:
  - generative-ai
  - ai-integration
  - educational-technology
  - higher-education
  - values
category:
  - Pedagogy
  - AI and technology
related:
  - '[[learning-alignment]]'
  - '[[A bitter lesson for higher education]]'
  - '[[AI literacy]]'
draft: false
slug: posts/ai-for-learning-at-scale
enableToc: true
reviewed:
  - writing_style
  - blog_writer
  - copy_editor
  - SEO_optimiser
---
> [!info] We've never had access to expertise at this scale
> Despite the ethical concerns, I can't think of another time in human history when so many people have had access to advanced expertise at this scale. Generative AI represents an unprecedented opportunity for learning—and I don't see why we should assume it won't keep getting better.

I understand the ethical concerns many have raised about [[large language models|generative AI]]. These are important issues that deserve thoughtful debate. I know these concerns and the critical position I'm meant to take as an academic working at the intersection of education and technology. I've spent fifteen years in that position and I know what that side looks like.

But here's the thing. Right now I have very little interest in an academic critique of generative AI.

Because even with all the ethical concerns that come with generative AI, I still think it represents an enormous, genuinely positive opportunity for *learning at scale*.

## What I believe about AI for learning at scale

Here are a few of my beliefs around generative AI:

- While existing foundation models are proprietary and closed, we're already seeing very good open-source models in the wild, and these open-source models will keep getting better.
- We will see a massive proliferation of models that will serve a wide range of values and philosophies. I want my models to be open-source and for me to have the ability to fine-tune them. I want to have some models for critical thinking, some for creativity, some for rationality, and so on.
- You'll have massive models that run in the cloud that you'll pay for, tiny models that run on your phone or other small devices, and mid-range models that institutions will use in-house.
- Just like you get to choose software and hardware today based on your personal values, you will have the same options with foundation AI models.
- Costs will continue coming down, and speed and utility will keep improving.
- The environmental impact of training and implementing AI models will not only be reduced; I think they will eventually give us insight into how to reduce climate change in other domains—a net benefit on the climate crisis.

As inconvenient, expensive, biased, opaque, and problematic as generative AI is, none of that changes the basic scale of what it makes possible.

I believe that generative AI is the first step towards accelerated learning at a scale and cost that makes all our previous attempts (universities, for instance) look like a rounding error.

The conclusion seems incontrovertible. If generative AI has the potential to enhance society through mass education at this scale, then pushing for its integration — even while open questions remain about the [[learning-alignment|risks and trade-offs]] — is the only reasonable position.

Based on what I've experienced in my own practice, I'm optimistic about the potential of this technology to expand access to advanced learning.

These models aren't perfect. Not even close. But I think it's misguided to hold back on the opportunities to accelerate learning at massive scale, across all sectors in society.

Of course, I might be wrong. I may have significant blind spots that mean I can't see what's obvious to everyone else. But I don't think I'm arguing from a position of ignorance — I'm aware of the counterarguments.

I just don't think they're relevant, given what's at stake.

> [!note] Provenance
> This post is based on an earlier article, "[My biased enthusiasm for generative AI, clearly articulated](https://www.mrowe.co.za/blog/2023/12/my-biased-enthusiasm-for-generative-ai-clearly-articulated/)", originally published on 16 December 2023.
