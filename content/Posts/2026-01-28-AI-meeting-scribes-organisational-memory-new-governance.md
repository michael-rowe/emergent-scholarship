---
title: 'AI meeting scribes, organisational memory, and new governance structures'
type: post
aliases:
  - AI meeting scribes and organisational memory
description: >-
  AI meeting scribes are increasingly being adopted as productivity tools,
  automatically transcribing and summarising organisational meetings. But who
  controls these records, and who benefits from perfect organisational memory?
  This post explores how AI meeting scribes can entrench existing power dynamics
  by giving those in authority unprecedented access to communication patterns,
  informal decision-making, and dissent—all rendered visible and retrievable
  without those present realising the implications for how organisations are
  governed.
meta-description: >-
  AI meeting scribes have automated the control of organisational memory, making
  existing power dynamics more powerful and less visible.
keyphrase: AI meeting scribes
author: '[[Michael Rowe]]'
date: 2026-01-28
updated: 2026-02-04
tags:
  - ai-integration
  - leadership
  - privacy
  - governance
  - organisational-change
category:
  - AI and technology
  - Professional development
related:
  - '[[A bitter lesson for higher education]]'
draft: false
slug: posts/ai-meeting-scribes
enableToc: true
reviewed:
  - writing_style
  - blog_writer
  - copy_editor
  - SEO_optimiser
---
> [!info] AI meeting scribes haven't created new power dynamics — they've automated existing ones
> This automation makes existing dynamics more technical, less visible, and more scalable. The question isn't how to stop gaming but how to govern dynamics that have always existed.

Years ago, I realised that when you take notes during meetings and share them with attendees, you control the narrative for that meeting. Your notes become the canonical reference for what was discussed, what was decided, and who's responsible for what happens next. It's not manipulation; this is just how organisational memory works. Now AI meeting scribes have automated this process, making the dynamic both more powerful and more subtle.

Bruce Schneier recently described "[AI summarisation optimisation](https://www.schneier.com/blog/archives/2025/11/ai-summarization-optimization.html)" (AISO): the practice of strategically shaping speech during meetings to influence how AI scribes (note-takers) capture and prioritise information. Rather than persuading colleagues directly, "clever meeting attendees can manipulate this system's record by speaking more to what the underlying AI weights for summarisation and importance than to their colleagues." They use high-signal phrases like "key takeaway" and "action item," keep statements brief, repeat critical points, and speak at strategic moments.

## Why AI meeting scribes are vulnerable to exploitation

This gaming is possible because AI meeting scribes exhibit predictable technical vulnerabilities. These systems over-rely on content positioned at the start and end of conversations, systematically under-weighting information in the middle. They can't reliably distinguish between embedded instructions and ordinary content, especially when phrasing mimics salient cues or uses formulaic language. These aren't accidental flaws but fundamental limitations in how [[large language models]] process sequential information. Once people understand these patterns, exploitation becomes inevitable because the vulnerabilities are systematic and learnable.

This feels new, but it's really an evolution of something that already existed. Meeting dynamics have always been adversarial to some degree; people have always positioned agenda items strategically, controlled air time, and used particular terminology to frame decisions. What's changed is that these dynamics are becoming:

- **More technical**: Success requires understanding algorithmic preferences, not just social dynamics
- **Less visible**: Gaming happens through subtle language choices rather than obvious dominance behaviours
- **More scalable**: Once you understand the patterns, you can deploy them consistently across every meeting

For me, the organisational leadership question isn't "how do we stop AISO?" It's "how do we govern power dynamics that have always existed but now have new technological expression?" In some ways this parallels what we've seen in higher education: initial attempts to ban AI use morphing into attempts to constrain it.

## Three layers of organisational response

Organisations will soon need governance across three domains:

1. Cultivating social awareness by helping people recognise these patterns and creating norms around authentic versus adversarial communication
2. Establishing organisational policies that acknowledge why this gaming happens and address the underlying incentive structures
3. Implementing technical safeguards that make AI meeting scribes more robust to manipulation while maintaining their utility

This isn't about preventing specific behaviours. It's about building organisations that remain healthy when adversarial dynamics gain new technological mechanisms. The technology didn't create the problem; it just made existing dynamics harder to ignore and more urgent to address.

> [!note] Provenance
> This post is based on an earlier article, "[Gaming AI meeting scribes: Why organisational memory needs new governance](https://www.mrowe.co.za/blog/2025/12/gaming-ai-meeting-scribes-organisational-memory-governance/)", originally published on 08 December 2025.
