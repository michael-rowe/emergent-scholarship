## The common architecture of literacy

After examining information literacy, media literacy, digital literacy, and data literacy, a consistent structural pattern emerges. Despite disciplinary differences and varying emphases, these literacies share six core dimensions:

### 1. Access and recognition

The ability to identify when a technology, information source, or medium is present and relevant, and to locate or access what's needed. This includes recognising different types and formats, understanding where they appear, and knowing how to engage with them.

### 2. Critical evaluation

The capacity to assess quality, reliability, accuracy, bias, and limitations. This involves questioning sources, understanding how systems work, recognising manipulation or error, and distinguishing high-quality from poor-quality outputs.

### 3. Functional application

The practical ability to use technologies or information effectively for specific purposes. This includes operational competence, understanding appropriate contexts for use, and deploying capabilities to achieve goals.

### 4. Creation and communication

The skill to generate new content, outputs, or solutions using the technology or medium, and to communicate effectively with or through it. This involves production, synthesis, and sharing of information or artefacts.

### 5. Ethical awareness and responsibility

Understanding the social, ethical, and civic implications of use. This includes recognising issues of privacy, equity, power, and impact on individuals and society, and making responsible choices that align with values.

### 6. Contextual judgement and metacognition

The development of taste, professional judgement, and self-awareness about one's own practice. This involves knowing when and how to apply capabilities appropriately, reflecting on effectiveness, and adapting practice based on context and experience.

This architecture reveals that literacy isn't merely skill acquisition or knowledge accumulation. It's a multidimensional capability that integrates understanding, critical thinking, practical competence, creative application, ethical reasoning, and reflective judgement.

## AI literacy through this lens

Applying this framework to AI literacy produces a clear definition:

**AI literacy is the multidimensional capability to recognise AI systems, critically evaluate their outputs and limitations, use them effectively for appropriate purposes, create meaningful outcomes through collaboration with AI, understand the ethical implications of AI engagement, and develop contextual judgement about when and how AI serves professional goals.**

This definition makes clear that AI literacy cannot be reduced to:

- Technical knowledge alone (understanding how LLMs work)
- Operational skill alone (knowing how to write prompts)
- Ethical awareness alone (recognising bias and limitations)
- Critical thinking alone (evaluating AI outputs)

Rather, AI literacy requires integration across all six dimensions, with particular emphasis on judgement and metacognition because AI engagement is inherently contextual and rapidly evolving.

The research literature confirms this multidimensional view. Long and Magerko's foundational 2020 framework identifies 17 competencies spanning recognition, understanding, evaluation, and critical engagement. UNESCO's 2024 framework emphasises knowledge, skills, and attitudes working together. Recent frameworks increasingly stress that AI literacy involves moving from consumer to interpreter to collaborator—a progression that requires developing all six dimensions.

## Assessing the course against AI literacy

Your 11-lesson course explicitly addresses all six dimensions of literacy:

### Access and recognition (Foundation lessons 1-2)

The course establishes AI as language-based cognitive extension rather than tool, search engine, or database. It teaches participants to recognise AI capabilities and limitations, understand when AI is present and useful, and identify appropriate contexts for engagement. This directly addresses the access and recognition dimension by helping academics understand what AI actually is and when it's relevant to their work.

### Critical evaluation (Throughout, but especially Transformation lesson 2)

The course repeatedly emphasises verification, critical evaluation of outputs, understanding complementary errors (where humans and AI make different mistakes), and recognising hallucinations and limitations. The "cultivating taste" lesson explicitly teaches evaluative judgement about AI engagement quality. This delivers the critical evaluation dimension by building systematic approaches to assessing AI outputs and processes.

### Functional application (Substitution and Adaptation lessons)

The course provides extensive practical training across multiple domains: content creation, reading for information, writing assistance, building competence, argument development, and problem decomposition. Participants learn structured prompting, iterative engagement, and domain-specific application across research, teaching, and administration. This comprehensively addresses functional application by teaching operational competence in context.

### Creation and communication (Adaptation lessons, Transformation lesson 1)

The course moves beyond consumption to creation—using AI to develop arguments, decompose problems, generate research questions, and produce scholarly outputs. The context sovereignty lesson teaches building persistent AI partnerships that enable ongoing creation. This dimension is strongly developed through the progression from substitution (AI does tasks) to adaptation (reshaping practice) to transformation (structural integration).

### Ethical awareness and responsibility (Throughout)

The course addresses transparency, attribution, verification as shared responsibility, avoiding over-reliance, understanding when AI undermines rather than supports goals, and maintaining scholarly voice and integrity. While not organised as a standalone "ethics module," ethical considerations are woven throughout practical lessons, appearing where they're most relevant to actual decisions.

### Contextual judgement and metacognition (Transformation lessons 2-3)

The "cultivating taste" lesson explicitly develops professional judgement about meaningful engagement versus superficial efficiency. The course teaches participants to distinguish genuine competence from familiarity, recognise when AI helps versus hinders, evaluate both outputs and processes, and develop domain-specific taste. The "integrating into practice" lesson provides frameworks for ongoing reflection and adaptation. This addresses the metacognitive dimension by making judgement development an explicit learning objective.

## The verdict: Does the course deliver AI literacy?

Yes. Someone who completes this course with genuine engagement would be AI literate according to the multidimensional framework above.

However, this conclusion requires three important qualifications:

### 1. Literacy requires practice, not just instruction

The course provides frameworks, techniques, and conceptual foundations, but literacy develops through sustained practice. The course explicitly acknowledges this—particularly in the taste cultivation lesson, which states that taste "develops through practice, reflection, and accumulated experience." A participant who passively reads the lessons but doesn't apply them won't become AI literate, just as reading about information literacy doesn't make someone information literate.

The course design anticipates this. Activities throughout require actual AI engagement, reflection on outcomes, and iterative refinement. The progression from substitution through adaptation to transformation assumes participants are actively working with AI throughout, not just learning about it.

### 2. AI literacy is developmental and contextual

The course recognises that AI literacy isn't binary (literate/illiterate) but developmental. Participants begin where they are and progress through increasing sophistication. The substitution-adaptation-transformation framework itself acknowledges stages of development.

Additionally, AI literacy is domain-specific. The course explicitly teaches that what constitutes meaningful AI engagement differs across research, teaching, and administration. Someone can be AI literate in one domain (e.g., using AI for writing) while still developing literacy in another (e.g., using AI for teaching).

### 3. The course delivers foundational AI literacy for academic contexts

The course is explicitly designed for academics engaging with generative AI for scholarly work. It delivers AI literacy as defined above within this context. It doesn't address every possible aspect of AI literacy—for example, it doesn't cover training AI models, contributing to AI development, or technical implementation of AI systems.

This scoping is appropriate. Just as information literacy for academics differs from information literacy for journalists or data scientists, AI literacy for academic workflow differs from AI literacy for other domains. The course delivers what academics need: the capability to recognise, evaluate, use, create with, reflect on, and make judgements about AI in their scholarly practice.

## The distinctive contribution

What makes this course particularly effective at developing AI literacy is its refusal to treat AI integration as purely technical. Many "AI for academics" courses focus primarily on the functional application dimension (here's how to write prompts, here's how to use AI for X task) with ethics bolted on at the end.

Your course integrates all six dimensions throughout. More importantly, it emphasises the two dimensions that distinguish literate from merely competent users: critical evaluation and contextual judgement. The course explicitly teaches participants to develop taste—professional judgement that can't be reduced to rules but develops through reflective practice.

The progression from substitution through adaptation to transformation mirrors the progression from novice to expert across literacy frameworks. Substitution develops functional competence. Adaptation develops critical evaluation and creative application. Transformation develops contextual judgement and metacognitive awareness.

This structural alignment with literacy frameworks—whether intentional or emergent—is what makes the course capable of delivering AI literacy rather than just AI skills.

## The challenge of assessment

The difficulty you're navigating is that AI literacy, like all literacies, is easier to recognise than to measure. You can assess whether someone knows how to write a structured prompt (functional application), but assessing whether they've developed good taste about meaningful engagement (contextual judgement) requires observing practice over time.

The course addresses this by emphasising reflection, documentation of learning, and progressive complexity. The activities create opportunities for participants to demonstrate developing literacy rather than just acquiring knowledge. But the true test of whether the course delivers AI literacy would be longitudinal: do participants continue to engage with AI thoughtfully six months after completion? Do they adapt their practice as AI capabilities evolve? Do they develop increasingly sophisticated judgement about meaningful engagement?

These questions can't be answered through end-of-course assessment. They require observing whether participants have internalised the frameworks and continue applying them independently—which is precisely what literacy means.

---

## Recommendation

You should reframe the course marketing from "AI for Academics" to explicitly foregrounding AI literacy. The course delivers AI literacy as rigorously defined by literacy frameworks. This positioning differentiates it from skills-focused courses and aligns with the course's actual pedagogical approach.

Consider language like:

- "Developing AI literacy for academic practice"
- "A comprehensive AI literacy course for academics"
- "Building AI literacy: From tools to judgement in academic work"

This reframing makes clear that the course isn't about learning tools—it's about developing multidimensional capability that integrates knowledge, skills, critical thinking, ethical awareness, and professional judgement. That's what you're delivering, and it's more valuable than tool training.