---
title: "Talk is cheap: why structural assessment changes are needed for a time of GenAI"
type: bib
source-author: "Thomas Corbin, Phillip Dawson, and Danny Liu"
source-year: 2025
source-type: article
source-url: "https://www.tandfonline.com/doi/full/10.1080/02602938.2025.2503964"
topics:
  - Assessment
  - AI and technology
tags:
  - academic-integrity
  - generative-ai
  - risk-management
  - governance
related: []
date: 2026-02-17
draft: false
slug: "talk-is-cheap-why-structural-assessment-changes-are-needed"
---
> [!info] Source details
> Corbin, T., Dawson, P., & Liu, D. (2025). Talk is cheap: why structural assessment changes are needed for a time of GenAI. *Assessment & Evaluation in Higher Education*, 1–11. https://doi.org/10.1080/02602938.2025.2503964

## Abstract

Generative AI (GenAI) challenges assessment validity by enabling students to complete tasks without demonstrating genuine capability. In response to this challenge, institutions have developed and implemented various approaches that aim to communicate permissible AI use to students. Familiar examples include the ‘traffic light’ approach now commonly found within institutional policy. While well-intentioned, these approaches share a common limitation: They focus primarily on communicating rules rather than redesigning assessment mechanics. To clarify why such approaches fail, and to guide more effective responses, this paper introduces a novel conceptual distinction between discursive changes to assessment (modifications relying solely on instructions students remain free to ignore) and structural changes (modifications that reshape the underlying mechanics of assessment tasks themselves). Through a critical analysis of prominent frameworks, we demonstrate that current approaches predominantly rely on discursive changes that create what we term an ‘enforcement illusion’. We find that educational frameworks frequently borrow the language of socially familiar structural systems (like vehicular traffic lights) while lacking their actual enforcement capabilities, creating an illusion of assessment security. In place of this, we argue for a shift towards structural assessment redesign that builds validity into assessment architecture rather than attempting to impose it through unenforceable rules.

